# HNSW 알고리즘 정리

RAG 같은 시스템에서 문서 청크를 임베딩 벡터로 저장해두면, 사용자의 질문도 임베딩해서 가장 비슷한 벡터를 찾아야 한다.

하지만 벡터가 100만 개처럼 많아지면, 연산의 양의 매우 많아지므로 매번 모든 벡터와 거리를 계산하는 방식은 너무 느리다.
그래서 사용하는 방식이 **ANN** 이다.

* **ANN:** 전체를 다 비교하지 않고 일부만 비교해도 실제 top_k와 비슷한 결과를 빠르게 얻는 방법
* **HNSW:** ANN을 구현하는 대표적인 그래프 기반 인덱스 알고리즘

## HNSW
HNSW는 벡터들을 **그래프** 로 표현한다. 이러한 그래프는 **노드**와 **간선**으로 이뤄져 있다.

* **노드:** 문서 청크의 임베딩 벡터
* **간선:** 서로 유사도가 비슷한 것 끼리 연결된 링크

그리고 이 그래프를 **여러개의 계층** 로 만든다.

* **최하위 계층:** 모든 노드가 존재하는 가장 촘촘한 그래프임 (나중에 정밀 탐색할때)
* **중간 계층:** 최상위보다 노드가 좀 더 밀도 있음
* **최상위 계층:** 일부 노드들만 존재하는 약간 덜떨어진 그래프 (그냥 함 유사한거 있나 훑어보는 용)

정리하면
* 위 계층은 노드가 적어서 대충 근처로 빠르게 이동하며 훑어봄
* 아래 계층은 촘촘해서 사용자 질문과 가장 유사한 결과 군집을 얻을 수 있음

## 계층 설정 과정
HNSW는 계층이 여러개가 있는데 막 복잡하거나 그런게 아니다.
쉽게 말하면 노드가 100만개 있다 할때, 최상위 그래프는 그중 몇 만개 정도만 가지고 있고, 밑으로 갈수록
가지는 노드들이 많아지며 최하위 노드는 100만개 전부를 가지고 있다. 그래프는 겹쳐져 있는게 아니며, 따로따로 존재한다. 

각 노드는 삽입될 때 최대 계층을 확률적으로 부여받는다.
이게 무슨 말이냐면
* **최하위 계층**은 노드가 삽일될 때 무조건 포함이 됨
* **중간 계층 이상**은 동전 던지기처럼 올라갈 확률에 따라 랜덤 결정

쉽게 말해 계층이 높아질수록 존재하는 노드 수는 급격히 줄어든다.
이 때문에 상위 계층은 대표 노드들만 있는 그냥 바람잡이 역할을 한다.

## 그래프 생성 과정

새 노드 **X**를 삽입할 때 대략 흐름은 다음과 같다.

1. **X**의 계층을 랜덤으로 부여 (최하위 계층은 그냥 기본 포함임)
2. 시작점에서 출발해, 상위 계층부터 탐색
3. 현재 노드의 친구 목록(M개 내외) 만 보며 유사도 계산을 통해 **X**와 더 가까운 이웃으로 이동
   이때 전부 비교하지 않고 **그래프를 타고 근처 후보만** 탐색하는거임
4. efConstruction(쉽게 말해 연결할 노드 모으는 바구니 같은거임) 만큼 후보를 넓게 유지/확장해 근처 후보를 모음
5. 그 후보 중 **X**와 가까운 노드 M개를 선택해 **X**의 친구로 저장
6. **양방향 연결:** 상대 노드 친구 목록에도 **X**를 추가하고, 필요하면 M개로 정리

삽입 과정에서도 전체 N개를 비교하지 않고, 그래프를 따라가며 방문한 후보들만 비교함.

## 검색은 어떻게 하나
사용자 질문 q가 들어오면:

1. 질문을 임베딩해서 q_vector 생성
2. 가장 높은 계층에서 시작노드부터 탐색
3. 상위 레벨에서는 보통 **그리디 탐색**을 한다 함:
   * 현재 노드의 친구들 중 q와 더 가까운 노드가 있으면 이동
   * 더 가까워질 수 없으면 그 노드를 들고 아래 계층로 내려감
4. 이 과정을 최하위 계층까지 반복
5. 최하위 계층에서는 보통 efSearch(후보군 모으는 바구니 같은거임)로 후보를 여러 개 유지하며 확장 탐색
6. 후보 집합에서 최종적으로 q와 가장 가까운 top_k 노드 반환

## RAG와 연결 흐름 대충 요약
HNSW로 top_k를 얻은 뒤 보통 RAG는 다음처럼 동작한다.

1. top_k 결과의 인덱스로 미리 저장해둔 문서 청크 텍스트를 가져옴
2. 그 텍스트를 프롬프트에 넣음
3. LLM이 근거 기반으로 답변 생성함

## 저거 HNSW에 나오는 파라미터들(이것들을 조정해가며 좋은 결과 나오려면 어느정도 값을 줘야하는지 알 수 있음)
* **`M`**: 노드가 유지하는 근처 노드 수의 상한
  * `M`이 증가하면 -> 그래프 연결성 상승, 정확도 상승 가능 그러나 메모리·구축비도 상승
* **`efConstruction`**: 삽입 시 후보를 얼마나 넓게 볼지
  * `efConstruction`이 증가하면 -> 그래프 구축 느림, 대신 그래프 품질 상승
* **`efSearch`**: 검색 시 후보를 얼마나 넓게 볼지 (검색 품질과 관련)
  * `efSearch`이 증가하면 -> 검색 느림, 대신 정확도 상승

## 정리
HNSW는 **가까운 것끼리 연결된 그래프**를 여러 레벨로 쌓아 상위 레벨에서 빠르게 근처로 이동하고, 
하위 레벨에서 후보를 넓게 탐색해 전체를 다 비교하지 않고도 top-k 근접 검색을 빠르게 수행하는 **ANN 인덱스**다.

## 공부하면서 대충 생각들?
와 이게 단순히 RAG만 볼때는 그냥 임베딩하고 대충 코사인 갈기고 하면 되는 그런 줄만 알았는데 좀 더 알아보려니까 관련 개념들이 많이 어렵더라. 이거 개념 숙지하는데만 3시간 넘게 걸린 듯.
물론 이미 누군가 만들어둔 모듈은 항상 존재하니까 개념도 어느정도 이해했겠다 걍 갖다 쓰면 되긴 한데, 코드상으론 어떻게 돌아갈지 궁금함. 이런거 대체 어떻게 구현했나 싶음.
다음엔 HNSW를 적용하기 위해 벡터 db 관련해서 공부해보자.

안그래도 전에 동아리 프로젝트때 기존에 만들었던 에이전트는 아직 잘 모를때라 원리 이유, 코드 왜 그렇게 쓰는지도 모르고 gpt나 여러 블로그 글 등을
난사해서 급하게 만든거라 그리 만족스럽지 않았음. 이번에 AI 에이전트 구축 관련해서 공부해서 다시 함 리부트 해봐야겠다.
